{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Enhanced data augmentation for better field robustness\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.35),                   # Increased from 0.1\n",
    "    layers.RandomZoom(0.35),                       # Increased from 0.1\n",
    "    layers.RandomContrast(0.45),                   # Increased from 0.3\n",
    "    layers.RandomBrightness(0.35),                 # Increased from 0.1\n",
    "    layers.RandomTranslation(0.25, 0.25),          # Added for positioning\n",
    "    layers.CenterCrop(200, 200),\n",
    "])\n",
    "\n",
    "# IMPROVED: Add attention mechanism for better feature focus\n",
    "def attention_block(x, filters):\n",
    "    # Squeeze-and-Excitation attention\n",
    "    se = layers.GlobalAveragePooling2D()(x)\n",
    "    se = layers.Dense(filters // 16, activation='relu')(se)\n",
    "    se = layers.Dense(filters, activation='sigmoid')(se)\n",
    "    se = layers.Reshape((1, 1, filters))(se)\n",
    "    return layers.Multiply()([x, se])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Your original model structure with key enhancements\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# Add improved data augmentation\n",
    "cnn.add(data_augmentation)\n",
    "cnn.add(layers.Rescaling(1./255))\n",
    "cnn.add(layers.GaussianNoise(0.15))  # Increased noise robustness\n",
    "\n",
    "# Block 1 - Your original structure with improvements\n",
    "cnn.add(layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(200, 200, 3)))\n",
    "cnn.add(layers.BatchNormalization())\n",
    "cnn.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "cnn.add(layers.BatchNormalization())\n",
    "cnn.add(layers.MaxPooling2D(2, 2))\n",
    "cnn.add(layers.Dropout(0.1))\n",
    "\n",
    "# Block 2 - Your original structure + attention\n",
    "cnn.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "cnn.add(layers.BatchNormalization())\n",
    "cnn.add(layers.Conv2D(64, 3, activation='relu'))\n",
    "cnn.add(layers.BatchNormalization())\n",
    "cnn.add(layers.Lambda(lambda x: attention_block(x, 64)))  # IMPROVED: Add attention\n",
    "cnn.add(layers.MaxPooling2D(2, 2))\n",
    "cnn.add(layers.Dropout(0.15))  # Slightly increased\n",
    "\n",
    "# Block 3 - Your original structure + attention\n",
    "cnn.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "cnn.add(layers.BatchNormalization())\n",
    "cnn.add(layers.Conv2D(128, 3, activation='relu'))\n",
    "cnn.add(layers.BatchNormalization())\n",
    "cnn.add(layers.Lambda(lambda x: attention_block(x, 128)))  # IMPROVED: Add attention\n",
    "cnn.add(layers.MaxPooling2D(2, 2))\n",
    "cnn.add(layers.Dropout(0.2))\n",
    "\n",
    "# Block 4 - Your original structure + attention\n",
    "cnn.add(layers.Conv2D(256, 3, padding='same', activation='relu'))\n",
    "cnn.add(layers.BatchNormalization())\n",
    "cnn.add(layers.Conv2D(256, 3, activation='relu'))\n",
    "cnn.add(layers.BatchNormalization())\n",
    "cnn.add(layers.Lambda(lambda x: attention_block(x, 256)))  # IMPROVED: Add attention\n",
    "cnn.add(layers.MaxPooling2D(2, 2))\n",
    "cnn.add(layers.Dropout(0.25))  # Increased\n",
    "\n",
    "# Block 5 - Your original structure + attention\n",
    "cnn.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
    "cnn.add(layers.BatchNormalization())\n",
    "cnn.add(layers.Conv2D(512, 3, activation='relu'))\n",
    "cnn.add(layers.BatchNormalization())\n",
    "cnn.add(layers.Lambda(lambda x: attention_block(x, 512)))  # IMPROVED: Add attention\n",
    "cnn.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "# IMPROVED: Enhanced output structure\n",
    "cnn.add(layers.Dropout(0.35))  # Increased from 0.3\n",
    "cnn.add(layers.GlobalAveragePooling2D())\n",
    "cnn.add(layers.Dense(1024, activation='relu'))  # Increased from 512\n",
    "cnn.add(layers.Dropout(0.5))\n",
    "cnn.add(layers.Dense(256, activation='relu'))   # Added extra layer\n",
    "cnn.add(layers.Dropout(0.3))\n",
    "cnn.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Enhanced training configuration\n",
    "# Warm restart cosine decay for better convergence\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "    initial_learning_rate=1.5e-3,  # Slightly higher initial LR\n",
    "    first_decay_steps=1000,\n",
    "    t_mul=2.0,\n",
    "    m_mul=0.9,\n",
    "    alpha=1e-6\n",
    ")\n",
    "\n",
    "# IMPROVED: Better optimizer with higher weight decay\n",
    "optimizer = tf.keras.optimizers.AdamW(\n",
    "    learning_rate=lr_schedule,\n",
    "    weight_decay=2e-4,  # Increased from 1e-4\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999\n",
    ")\n",
    "\n",
    "# IMPROVED: Enhanced focal loss for better classification\n",
    "def improved_focal_loss(alpha=0.3, gamma=2.5):  # Adjusted parameters\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        p_t = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        alpha_factor = tf.ones_like(y_true) * alpha\n",
    "        alpha_t = tf.where(tf.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "        cross_entropy = -tf.math.log(p_t)\n",
    "        weight = alpha_t * tf.pow((1 - p_t), gamma)\n",
    "        loss = weight * cross_entropy\n",
    "        return tf.reduce_mean(tf.reduce_sum(loss, axis=1))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "cnn.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss=improved_focal_loss(),\n",
    "    metrics=['accuracy', 'top_k_categorical_accuracy']  # Added top-k metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Calculate class weights for balanced training\n",
    "def get_class_weights(dataset):\n",
    "    labels = []\n",
    "    for _, label_batch in dataset:\n",
    "        labels.extend(np.argmax(label_batch.numpy(), axis=1))\n",
    "    \n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(labels),\n",
    "        y=labels\n",
    "    )\n",
    "    return dict(enumerate(class_weights))\n",
    "\n",
    "class_weights = get_class_weights(train_ds)\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Enhanced callbacks with more sophisticated monitoring\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=25,  # Increased patience\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        min_delta=0.001  # Added minimum improvement threshold\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,  # More aggressive reduction\n",
    "        patience=8,  # Increased patience\n",
    "        min_lr=1e-8,\n",
    "        verbose=1,\n",
    "        cooldown=3  # Added cooldown period\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'ImprovedEnhancedRiceModel.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_weights_only=False\n",
    "    ),\n",
    "    # IMPROVED: Add learning rate logging\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Optimize dataset performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# IMPROVED: Enhanced training with class weights\n",
    "EPOCHS = 75  # Increased epochs for better convergence\n",
    "\n",
    "print(\"Starting improved enhanced training...\")\n",
    "history = cnn.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,  # IMPROVED: Add class balancing\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Enhanced evaluation and visualization\n",
    "def plot_improved_training_history(history):\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Top-K Accuracy\n",
    "    if 'top_k_categorical_accuracy' in history.history:\n",
    "        ax3.plot(history.history['top_k_categorical_accuracy'], label='Training Top-K', linewidth=2)\n",
    "        ax3.plot(history.history['val_top_k_categorical_accuracy'], label='Validation Top-K', linewidth=2)\n",
    "        ax3.set_title('Top-K Accuracy', fontsize=14, fontweight='bold')\n",
    "        ax3.set_xlabel('Epoch')\n",
    "        ax3.set_ylabel('Top-K Accuracy')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate\n",
    "    if 'lr' in history.history:\n",
    "        ax4.plot(history.history['lr'], linewidth=2, color='red')\n",
    "        ax4.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "        ax4.set_xlabel('Epoch')\n",
    "        ax4.set_ylabel('Learning Rate')\n",
    "        ax4.set_yscale('log')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_improved_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Comprehensive evaluation and save\n",
    "print(\"Evaluating improved enhanced model...\")\n",
    "test_loss, test_acc, test_top_k = cnn.evaluate(val_ds, verbose=0)\n",
    "print(f\"Improved Model Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Improved Model Top-K Accuracy: {test_top_k:.4f}\")\n",
    "print(f\"Improved Model Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Save the improved model\n",
    "cnn.save('ImprovedEnhancedCNN.keras')\n",
    "print(\"Improved model saved as 'ImprovedEnhancedCNN.keras'\")\n",
    "\n",
    "# IMPROVED: Save training history\n",
    "import pickle\n",
    "with open('improved_training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "print(\"Training history saved as 'improved_training_history.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
